# Museum Pulse Final Project

Интерактивная инсталляция «Museum Pulse» сопоставляет визуальные эффекты с текущим пульсом посетителя, который оценивается бесконтактно по видеопотоку. Данный репозиторий содержит прототип системы на Python с модулем rPPG, сервисной панелью, транспортным уровнем (WebSocket/OSC) и демо-визуализацией на основе Python. Проект построен на идеях из [webcam-pulse-detector](https://github.com/thearn/webcam-pulse-detector) и современных rPPG-фреймворков (pyVHR, rPPG-Toolbox).

## Содержание

- [Архитектура](#архитектура)
- [Установка](#установка)
- [Запуск](#запуск)
- [Стрим BPM](#стрим-bpm)
- [Инструкции для музейных сотрудников](#инструкции-для-музейных-сотрудников)
- [Техразбор алгоритма](#техразбор-алгоритма)
- [Демо-визуализация](#демо-визуализация)
- [Расширение и сравнение методов](#расширение-и-сравнение-методов)
- [Требования и рекомендации](#требования-и-рекомендации)

## Архитектура

```
MuseumPulseFinal/
├── README.md
├── requirements.txt
└── src/
    ├── main.py                 # Точка входа, цикл обработки кадров
    └── museumpulse/
        ├── rppg/               # Детекция лица и извлечение rPPG-сигнала
        │   ├── detector.py
        │   ├── quality.py
        │   ├── roi.py
        │   ├── signal_processing.py
        │   └── types.py
        ├── transport/          # Выходные каналы
        │   ├── osc_sender.py
        │   └── websocket_server.py
        ├── ui/
        │   └── service_panel.py
        └── utils/
            ├── data_logger.py
            └── logging.py
```

Основные компоненты:

- **Модуль rPPG**: захват ROI на лбу (Haar Cascade) с экспоненциальной стабилизацией окна, усреднение зелёного канала, детрендинг, полосовая фильтрация (0.7–4.0 Гц), спектральная оценка и расчёт BPM+SNR.
- **Сервисная панель**: превью кадра с подсвеченными ROI, текущие BPM/SNR/статус, возможность остановки по `Q`.
- **Транспорт**: рассылка BPM по WebSocket (JSON) и OSC (`/bpm`).
- **Логирование**: запись CSV с таймштампом, BPM, SNR и состоянием окна.

## Установка

1. Подготовить окружение Python 3.10+:

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

2. Для Windows убедитесь, что установлены пакеты Visual C++ Redistributable. Для Linux рекомендуется установить `libgl1` (для OpenCV) и протестировать доступ к UVC-камере (`/dev/video*`).

## Запуск

```bash
export PYTHONPATH=src  # Windows PowerShell: $env:PYTHONPATH = "src"
python -m museumpulse.main --source 0 --width 1280 --height 720 --log session.csv
# Альтернатива: python src/main.py --source 0 ...
```

Параметры:

- `--source`: индекс камеры (0/1/...) или путь к видеофайлу.
- `--window` / `--min-window`: длина и минимальная заполненность скользящего окна (секунды).
- `--bpm-range`: доверительный диапазон BPM (по умолчанию 45–160).
- `--no-ui`: запуск без сервисной панели (для headless-режима).
- `--no-websocket` / `--no-osc`: отключение соответствующих каналов.
- `--log`: путь к CSV логу (по умолчанию логирование отключено).

Программа завершает работу по нажатию `Q` в окне превью или по `Ctrl+C` в консоли.

## Стрим BPM

### WebSocket

- Сервер доступен на `ws://<host>:8765/` (порт меняется флагом `--websocket-port`).
- Клиент получает JSON вида:

  ```json
  {
    "timestamp": 1715774893.532,
    "bpm": 72.4,
    "raw_bpm": 74.9,
    "snr": 8.1,
    "quality": "good",
    "status": "ok",
    "window_duration": 26.5
  }
  ```

### OSC

- UDP-адрес: `/bpm` (порт задаётся `--osc-port`).
- Передаётся одно значение — текущий BPM. Доступно выключение флагом `--no-osc`.

## Инструкции для музейных сотрудников

1. **Подготовка стенда**: установить стенд на расстоянии 0.6–1.5 м от посетителя, обеспечить фронтальное освещение 300–500 лк без мерцания (желательно светодиодные панели без PWM).
2. **Запуск системы**: включить ПК, активировать виртуальное окружение Python и запустить команду из раздела «Запуск». Убедиться, что сервисная панель показывает лицо и ROI на лбу (зелёный прямоугольник).
3. **Мониторинг качества**: индикатор `Quality` показывает `good/moderate/poor`. При `poor` или статусе `unstable` попросите посетителя занять статичное положение или скорректируйте свет.
4. **Перезапуск камеры**: при утрате видеопотока программа автоматически пытается возобновить кадры. Если проблема сохраняется, закройте приложение (`Q`), переподключите камеру и запустите снова.
5. **Визуализация**: модуль визуализации (TouchDesigner/Unity/Processing) должен подписываться на WebSocket или OSC и преобразовывать BPM в интенсивность эффекта (пример — частота вспышек).

## Техразбор алгоритма

1. **ROI**: используется центральный участок лба. Он менее подвижен и содержит устойчивый фотоплетизмографический сигнал. Исследования показывают, что лоб и щеки обладают максимальной амплитудой rPPG-сигнала при стандартном освещении (Wang et al., 2017).
2. **Зелёный канал**: кровь лучше поглощает зелёный диапазон (около 525 нм), что даёт максимальную амплитуду отражённого сигнала (Verkruysse et al., 2008). Поэтому усредняем зелёный канал ROI.
3. **Предобработка**: устраняем тренд (детрендинг), затем применяем полосовой фильтр 0.7–4.0 Гц, чтобы выделить физиологический диапазон пульса и убрать дыхание/дрейф.
4. **Спектральная оценка**: расчёт периодограммы/FFT. Максимум мощности в диапазоне 0.75–3 Гц → BPM = `f * 60`.
5. **SNR**: отношение мощности основного пика к остальной полосе. Используется для классификации качества (`good/moderate/poor`).

## Демо-визуализация

Для проверки интеграции можно использовать небольшие Python-скрипты (Processing/p5.js/TouchDesigner не требуются на этапе пилота). В директории `examples/` доступны:

- `simple_particles.py` — облако частиц, интенсивность и радиус которых следуют за BPM.
- `pulse_light_wall.py` — световая панель «Pulse Light Wall», которая мерцает в такт сердцу и меняет цвет от синего к красному по мере роста BPM.

Оба клиента автоматически используют сглаженное значение BPM, но при необходимости могут переключиться на «сырое» значение (`raw_bpm`).

## Расширение и сравнение методов

- **pyVHR**: позволяет протестировать алгоритмы CHROM, POS, PBV и др. Рекомендуется использовать ноутбук `notebooks/pyvhr_benchmark.ipynb` (подготовьте самостоятельно) для сравнения MAE на записанных сессиях.
- **rPPG-Toolbox**: содержит набор датасетов и пайплайнов. Можно использовать его метрики для валидации устойчивости к движению.
- Для повышения точности добавьте стабилизацию ROI (отслеживание ключевых точек), адаптивное сглаживание BPM и фильтрацию по индикатору движения.

## Требования и рекомендации

- Задержка от кадра до BPM ≤ 3 с достигается благодаря окну 20–30 с и обновлению раз в 1 с.
- Для MAE ≤ 5 BPM необходимо статичное положение и ровный свет. Используйте режим `moderate/good` как индикатор надёжности.
- Система протестирована на камерах UVC 1080p@30fps под Windows и Linux.
- Для непрерывной работы (8 ч) запускайте приложение в `tmux`/`systemd`, ведите логи в CSV. В случае сбоев видеопотока возможен автоматический рестарт по внешнему watchdog-скрипту.

## Ссылки

- Verkruysse, W., Svaasand, L. O., & Nelson, J. S. (2008). *Remote plethysmographic imaging using ambient light.* Optics Express.
- Wang, W., den Brinker, A. C., Stuijk, S., & de Haan, G. (2017). *Algorithmic principles of remote PPG.* IEEE Transactions on Biomedical Engineering.
- Tulyakov, S., Alameda-Pineda, X., Ricci, E., Yin, L., Cohn, J. F., & Sebe, N. (2016). *Self-adaptive matrix completion for heart rate estimation from facial videos.* CVPR.
